{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM+47ZzvThyeIESSMbesmKI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plaban1981/Hugging_Face_transformers_topics/blob/main/Audio_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlpFb86DiaW8",
        "outputId": "80378ace-58cf-4b5e-b305-086e24063e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.8 MB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 52.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 43.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/openai/whisper.git "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4_xJEhViy15",
        "outputId": "5e569e6f-62ef-48b0-853a-e29ab6f0245d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-6q9lkgbg\n",
            "  Running command git clone -q https://github.com/openai/whisper.git /tmp/pip-req-build-6q9lkgbg\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.19.0 in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (4.25.1)\n",
            "Collecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.16.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (0.11.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers>=4.19.0->whisper==1.0) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.24.3)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.0-py3-none-any.whl size=1175315 sha256=69df2ef50b92a34d57ed70f792abbeaf5b66aed7444df49a75f5b9fd60d2b55a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-egsfjq42/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\n",
            "Successfully built whisper\n",
            "Installing collected packages: ffmpeg-python, whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 whisper-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "transformers.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "m92DOPAEiyMV",
        "outputId": "9d4384ec-e1f8-434f-90e8-26ff235efe6d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.25.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFafUFnCi3cL",
        "outputId": "5ca4f271-70da-4afb-8a87-a032d3fe4d7b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download youtube video"
      ],
      "metadata": {
        "id": "zmN1M1gB2LxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install youtube-dl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry1tE2hC2RI8",
        "outputId": "650054c3-cfa4-462f-8b9f-2e377db9b35f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting youtube-dl\n",
            "  Downloading youtube_dl-2021.12.17-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 4.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: youtube-dl\n",
            "Successfully installed youtube-dl-2021.12.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals\n",
        "import youtube_dl\n",
        "\n",
        "\n",
        "ydl_opts = {\n",
        "    'format': 'bestaudio/best',\n",
        "    'postprocessors': [{\n",
        "        'key': 'FFmpegExtractAudio',\n",
        "        'preferredcodec': 'wav',\n",
        "        'preferredquality': '192',\n",
        "    }],\n",
        "    'outtmpl':\".\" + '/video.%(ext)s',\n",
        "}\n",
        "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "    ydl.download(['https://www.youtube.com/watch?v=srSNZlbhCwk&t=3s'])\n",
        "    \n",
        "absolute_path = \"video.wav\" #file name of your downloaded audio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOHt86zj2bIT",
        "outputId": "3c4b1a80-6101-4223-cf0d-7b799b67438f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] srSNZlbhCwk: Downloading webpage\n",
            "[download] Destination: ./video.webm\n",
            "[download] 100% of 763.32KiB in 00:11\n",
            "[ffmpeg] Destination: ./video.wav\n",
            "Deleting original file ./video.webm (pass -k to keep)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transcribe text from Audio"
      ],
      "metadata": {
        "id": "de7JA09ei9xN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"large\")\n",
        "options = dict(language='en', beam_size=5, best_of=5)\n",
        "#transcribe_options = dict(task=\"transcribe\", **options)\n",
        "translate_options = dict(task=\"translate\", **options)\n",
        "translation = model.transcribe(\"/content/video.wav\", **translate_options)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7XYvXwPk7kH",
        "outputId": "6d872b8c-8fcd-4dd7-9dd5-7deaeceb774e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 2.87G/2.87G [00:22<00:00, 136MiB/s]\n",
            "/usr/local/lib/python3.8/dist-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S29zdo7q6nYL",
        "outputId": "5b5c116b-1824-422c-9af2-be37e7f20238"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': \" This happened when I was 12 years old, I went to my grandmother's house with my mom My uncle had a computer at that time, which had a lot of games, so I started playing games as soon as I went there It was night and everyone went to attend the wedding in a nearby village except me Because I wanted to play games on the computer, then my uncle called me that his car has been punctured There is a tire in the house, we are close, come with the tire When I went to him, I saw that a strange thing was sitting, I asked him who are you Then he showed his face, which was very scary, then I noticed that he was just up to the stomach I ran immediately from there, but I fainted while running, when my eyes opened, I was at my grandmother's house I still don't know what it was\",\n",
              " 'segments': [{'id': 0,\n",
              "   'seek': 0,\n",
              "   'start': 0.0,\n",
              "   'end': 5.4,\n",
              "   'text': \" This happened when I was 12 years old, I went to my grandmother's house with my mom\",\n",
              "   'tokens': [639,\n",
              "    2011,\n",
              "    562,\n",
              "    286,\n",
              "    390,\n",
              "    2272,\n",
              "    924,\n",
              "    1331,\n",
              "    11,\n",
              "    286,\n",
              "    1437,\n",
              "    281,\n",
              "    452,\n",
              "    14317,\n",
              "    311,\n",
              "    1782,\n",
              "    365,\n",
              "    452,\n",
              "    1225],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3603224073137556,\n",
              "   'compression_ratio': 1.6905660377358491,\n",
              "   'no_speech_prob': 0.05138559639453888},\n",
              "  {'id': 1,\n",
              "   'seek': 0,\n",
              "   'start': 5.4,\n",
              "   'end': 11.4,\n",
              "   'text': ' My uncle had a computer at that time, which had a lot of games, so I started playing games as soon as I went there',\n",
              "   'tokens': [1222,\n",
              "    9153,\n",
              "    632,\n",
              "    257,\n",
              "    3820,\n",
              "    412,\n",
              "    300,\n",
              "    565,\n",
              "    11,\n",
              "    597,\n",
              "    632,\n",
              "    257,\n",
              "    688,\n",
              "    295,\n",
              "    2813,\n",
              "    11,\n",
              "    370,\n",
              "    286,\n",
              "    1409,\n",
              "    2433,\n",
              "    2813,\n",
              "    382,\n",
              "    2321,\n",
              "    382,\n",
              "    286,\n",
              "    1437,\n",
              "    456],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3603224073137556,\n",
              "   'compression_ratio': 1.6905660377358491,\n",
              "   'no_speech_prob': 0.05138559639453888},\n",
              "  {'id': 2,\n",
              "   'seek': 0,\n",
              "   'start': 11.4,\n",
              "   'end': 16.6,\n",
              "   'text': ' It was night and everyone went to attend the wedding in a nearby village except me',\n",
              "   'tokens': [467,\n",
              "    390,\n",
              "    1818,\n",
              "    293,\n",
              "    1518,\n",
              "    1437,\n",
              "    281,\n",
              "    6888,\n",
              "    264,\n",
              "    8523,\n",
              "    294,\n",
              "    257,\n",
              "    11184,\n",
              "    7288,\n",
              "    3993,\n",
              "    385],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3603224073137556,\n",
              "   'compression_ratio': 1.6905660377358491,\n",
              "   'no_speech_prob': 0.05138559639453888},\n",
              "  {'id': 3,\n",
              "   'seek': 0,\n",
              "   'start': 16.6,\n",
              "   'end': 22.5,\n",
              "   'text': ' Because I wanted to play games on the computer, then my uncle called me that his car has been punctured',\n",
              "   'tokens': [1436,\n",
              "    286,\n",
              "    1415,\n",
              "    281,\n",
              "    862,\n",
              "    2813,\n",
              "    322,\n",
              "    264,\n",
              "    3820,\n",
              "    11,\n",
              "    550,\n",
              "    452,\n",
              "    9153,\n",
              "    1219,\n",
              "    385,\n",
              "    300,\n",
              "    702,\n",
              "    1032,\n",
              "    575,\n",
              "    668,\n",
              "    27006,\n",
              "    3831],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3603224073137556,\n",
              "   'compression_ratio': 1.6905660377358491,\n",
              "   'no_speech_prob': 0.05138559639453888},\n",
              "  {'id': 4,\n",
              "   'seek': 0,\n",
              "   'start': 22.5,\n",
              "   'end': 26.400000000000002,\n",
              "   'text': ' There is a tire in the house, we are close, come with the tire',\n",
              "   'tokens': [821,\n",
              "    307,\n",
              "    257,\n",
              "    11756,\n",
              "    294,\n",
              "    264,\n",
              "    1782,\n",
              "    11,\n",
              "    321,\n",
              "    366,\n",
              "    1998,\n",
              "    11,\n",
              "    808,\n",
              "    365,\n",
              "    264,\n",
              "    11756],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3603224073137556,\n",
              "   'compression_ratio': 1.6905660377358491,\n",
              "   'no_speech_prob': 0.05138559639453888},\n",
              "  {'id': 5,\n",
              "   'seek': 2640,\n",
              "   'start': 26.4,\n",
              "   'end': 32.199999999999996,\n",
              "   'text': ' When I went to him, I saw that a strange thing was sitting, I asked him who are you',\n",
              "   'tokens': [1133,\n",
              "    286,\n",
              "    1437,\n",
              "    281,\n",
              "    796,\n",
              "    11,\n",
              "    286,\n",
              "    1866,\n",
              "    300,\n",
              "    257,\n",
              "    5861,\n",
              "    551,\n",
              "    390,\n",
              "    3798,\n",
              "    11,\n",
              "    286,\n",
              "    2351,\n",
              "    796,\n",
              "    567,\n",
              "    366,\n",
              "    291],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.30966191011316635,\n",
              "   'compression_ratio': 1.5679611650485437,\n",
              "   'no_speech_prob': 2.2244217689149082e-05},\n",
              "  {'id': 6,\n",
              "   'seek': 2640,\n",
              "   'start': 32.199999999999996,\n",
              "   'end': 37.6,\n",
              "   'text': ' Then he showed his face, which was very scary, then I noticed that he was just up to the stomach',\n",
              "   'tokens': [1396,\n",
              "    415,\n",
              "    4712,\n",
              "    702,\n",
              "    1851,\n",
              "    11,\n",
              "    597,\n",
              "    390,\n",
              "    588,\n",
              "    6958,\n",
              "    11,\n",
              "    550,\n",
              "    286,\n",
              "    5694,\n",
              "    300,\n",
              "    415,\n",
              "    390,\n",
              "    445,\n",
              "    493,\n",
              "    281,\n",
              "    264,\n",
              "    9665],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.30966191011316635,\n",
              "   'compression_ratio': 1.5679611650485437,\n",
              "   'no_speech_prob': 2.2244217689149082e-05},\n",
              "  {'id': 7,\n",
              "   'seek': 2640,\n",
              "   'start': 37.6,\n",
              "   'end': 43.4,\n",
              "   'text': \" I ran immediately from there, but I fainted while running, when my eyes opened, I was at my grandmother's house\",\n",
              "   'tokens': [286,\n",
              "    5872,\n",
              "    4258,\n",
              "    490,\n",
              "    456,\n",
              "    11,\n",
              "    457,\n",
              "    286,\n",
              "    21104,\n",
              "    292,\n",
              "    1339,\n",
              "    2614,\n",
              "    11,\n",
              "    562,\n",
              "    452,\n",
              "    2575,\n",
              "    5625,\n",
              "    11,\n",
              "    286,\n",
              "    390,\n",
              "    412,\n",
              "    452,\n",
              "    14317,\n",
              "    311,\n",
              "    1782],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.30966191011316635,\n",
              "   'compression_ratio': 1.5679611650485437,\n",
              "   'no_speech_prob': 2.2244217689149082e-05},\n",
              "  {'id': 8,\n",
              "   'seek': 4340,\n",
              "   'start': 43.4,\n",
              "   'end': 56.8,\n",
              "   'text': \" I still don't know what it was\",\n",
              "   'tokens': [50364, 286, 920, 500, 380, 458, 437, 309, 390, 51034],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4710715033791282,\n",
              "   'compression_ratio': 0.7894736842105263,\n",
              "   'no_speech_prob': 0.0032498794607818127}],\n",
              " 'language': 'en'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "fQltOyu3nkuX",
        "outputId": "8cad770c-9964-4410-a627-b524955c9ae4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" This is when I was 12 years old, I once went to my grandmother's house with my mom. My uncle had a computer at that time, which had a lot of games, so I started playing games as soon as I went there. It was night and everyone went to attend the wedding in a nearby village, except me. Because I had to play games on the computer, then my uncle called me that his car has a puncture. There is a tire in the house, we are nearby, come with the tire. When I reached him, I saw that a strange thing was sitting, I asked him who you are. So he showed his face, which was very scary, then I noticed that it was just up to the stomach. I ran away from there, but while running I fainted. When I woke up, I was at my grandmother's house, I still don't know what it was.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(model,'transcribe.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBNCFY71qkyU",
        "outputId": "497bb68b-0e32-4866-a359-ffe4c58d133b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['transcribe.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the Automatic Speech Recognition Pipeline"
      ],
      "metadata": {
        "id": "pnGs9MTfszn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline(task=\"automatic-speech-recognition\", model=\"openai/whisper-large\",max_length=5000)\n",
        "pipe(\"/content/video.wav\")"
      ],
      "metadata": {
        "id": "kSxBgUQ2cDGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zeroshot classification using transformers"
      ],
      "metadata": {
        "id": "eDepRUm9i4SQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.section.io/engineering-education/how-to-implement-zero-shot-classification-using-python/#:~:text=Zero-shot%20classification%20is%20a%20technique%20that%20allows%20us,topic%2C%20emotion%2C%20or%20event%20described%20by%20the%20label."
      ],
      "metadata": {
        "id": "XZlQV8hrptCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "classifier_pipeline = pipeline (\"zero-shot-classification\", model = \"facebook/bart-large-mnli\")"
      ],
      "metadata": {
        "id": "8JAjDgGOi8N1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the zeroshot pipeline"
      ],
      "metadata": {
        "id": "BTOvnPLWr4KO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_pipeline.save_pretrained(\"zeroshot\")"
      ],
      "metadata": {
        "id": "heMwchl9ptUU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\" This is when I was 12 years old, I once went to my grandmother's house with my mom. My uncle had a computer at that time, which had a lot of games, so I started playing games as soon as I went there. It was night and everyone went to attend the wedding in a nearby village, except me. Because I had to play games on the computer, then my uncle called me that his car has a puncture. There is a tire in the house, we are nearby, come with the tire. When I reached him, I saw that a strange thing was sitting, I asked him who you are. So he showed his face, which was very scary, then I noticed that it was just up to the stomach. I ran away from there, but while running I fainted. When I woke up, I was at my grandmother's house, I still don't know what it was.\"\"\""
      ],
      "metadata": {
        "id": "7VJExfmLqdfy"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_pipeline = pipeline (\"zero-shot-classification\", model = \"/content/zeroshot\")\n",
        "label_candidate = ['horror', 'comedy', 'sentimental','romantic','seroius']\n",
        "new_pipeline(text, label_candidate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUGNXhB5qBPC",
        "outputId": "728d0a53-f75b-4f60-c0e5-7028bb4a266a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': \" This is when I was 12 years old, I once went to my grandmother's house with my mom. My uncle had a computer at that time, which had a lot of games, so I started playing games as soon as I went there. It was night and everyone went to attend the wedding in a nearby village, except me. Because I had to play games on the computer, then my uncle called me that his car has a puncture. There is a tire in the house, we are nearby, come with the tire. When I reached him, I saw that a strange thing was sitting, I asked him who you are. So he showed his face, which was very scary, then I noticed that it was just up to the stomach. I ran away from there, but while running I fainted. When I woke up, I was at my grandmother's house, I still don't know what it was.\",\n",
              " 'labels': ['horror', 'seroius', 'sentimental', 'comedy', 'romantic'],\n",
              " 'scores': [0.6341521739959717,\n",
              "  0.18177475035190582,\n",
              "  0.12192074954509735,\n",
              "  0.037401482462882996,\n",
              "  0.02475087158381939]}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_candidate = ['Positive', 'Negative', 'Neutral']\n",
        "classifier_pipeline (translation['text'], label_candidate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm2kB9C_pb_N",
        "outputId": "0e98b440-538d-4aa3-dbc5-ebcb52d14204"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': \" This is when I was 12 years old, I once went to my grandmother's house with my mom. My uncle had a computer at that time, which had a lot of games, so I started playing games as soon as I went there. It was night and everyone went to attend the wedding in a nearby village, except me. Because I had to play games on the computer, then my uncle called me that his car has a puncture. There is a tire in the house, we are nearby, come with the tire. When I reached him, I saw that a strange thing was sitting, I asked him who you are. So he showed his face, which was very scary, then I noticed that it was just up to the stomach. I ran away from there, but while running I fainted. When I woke up, I was at my grandmother's house, I still don't know what it was.\",\n",
              " 'labels': ['Negative', 'Positive', 'Neutral'],\n",
              " 'scores': [0.520041286945343, 0.24548503756523132, 0.23447363078594208]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Huggingface whisper model"
      ],
      "metadata": {
        "id": "PvcfYlKIsPqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration,WhisperFeatureExtractor"
      ],
      "metadata": {
        "id": "Rnxg5raD--Oq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\")\n",
        "feature = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-large\")\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large\")"
      ],
      "metadata": {
        "id": "KnjH4vMn--81"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newm = whisper.load_audio('/content/video.wav')"
      ],
      "metadata": {
        "id": "nLDC5T6YBJPb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newm.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqpPM4oPequL",
        "outputId": "76777127-0566-43fc-9ec7-f5ce95efddbd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(731440,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation = newm.transcribe(\"/content/Audio1.mp3\", **translate_options)\n"
      ],
      "metadata": {
        "id": "aFoKqcMRBZqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration,WhisperFeatureExtractor\n",
        "\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny.en\")\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny.en\")\n",
        "\n",
        "inputs = processor(np.array(newm), return_tensors=\"pt\")\n",
        "input_features = inputs.input_features\n",
        "\n",
        "generated_ids = model.generate(inputs=input_features)\n",
        "\n",
        "transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "transcription"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "-BHBQFiH9y3-",
        "outputId": "5ac87990-99c6-458d-a1f6-f589473f08be"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1387: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young man, and I am a young'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9aWe6UJm3gC",
        "outputId": "cc8cf109-6af7-4e08-fb21-f92bc28ea7af"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (0.8.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.4.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (4.13.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.43.0->librosa) (3.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Librosa can handle videos spanning upto 30 seconds"
      ],
      "metadata": {
        "id": "g55M8aHhq0o0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "import librosa\n",
        "\n",
        "speech, _ = librosa.load(\"/content/video.wav\")\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\")\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large\")\n",
        "\n",
        "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language = \"en\", task = \"transcribe\")\n",
        "input_features = processor(speech, return_tensors=\"pt\").input_features \n",
        "predicted_ids = model.generate(input_features,max_length=1000)\n",
        "transcription = processor.batch_decode(predicted_ids)\n",
        "\n",
        "print(processor.batch_decode(predicted_ids, skip_special_tokens = True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG8S0BA1lvsP",
        "outputId": "ff9b3e95-df5a-4a8a-e89a-c7f4d99098fe"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\" This is when I was 12 years old, I went to my grandmother's house with my mom. My uncle had a computer at that time, which had a lot of games, so I went there and started playing games. It was night and everyone went to attend the wedding in a nearby village except me, because I wanted to play games on the computer. Then my uncle called me and said that his car's\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_ids = model.generate(input_features,max_new_tokens=3000)\n",
        "transcription = processor.batch_decode(predicted_ids)\n",
        "\n",
        "print(processor.batch_decode(predicted_ids, skip_special_tokens = True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPUM5DpXpDsF",
        "outputId": "818179d1-3c87-4e8b-f5e1-74457297c25c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\" This is when I was 12 years old, I went to my grandmother's house with my mom. My uncle had a computer at that time, which had a lot of games, so I went there and started playing games. It was night and everyone went to attend the wedding in a nearby village except me, because I wanted to play games on the computer. Then my uncle called me and said that his car's\"]\n"
          ]
        }
      ]
    }
  ]
}