{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPoZTFK7b7KY7nCY8C/wQ6X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plaban1981/Hugging_Face_transformers_topics/blob/main/Audio_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nlpFb86DiaW8"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers==4.24.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCDx3ezwOwQq",
        "outputId": "93da4ad1-0036-4f4b-bd73-b156472210b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (0.8.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.11.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.4.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.7.3)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (4.13.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (59.5.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.25.11)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.43.0->librosa) (3.11.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/openai/whisper.git "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4_xJEhViy15",
        "outputId": "a950464b-9584-4e37-cb88-0b76a484d4c1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-3_wc89l9\n",
            "  Running command git clone -q https://github.com/openai/whisper.git /tmp/pip-req-build-3_wc89l9\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (1.13.0+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.19.0 in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (4.20.1)\n",
            "Collecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (3.8.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (0.11.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers>=4.19.0->whisper==1.0) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.0.4)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.0-py3-none-any.whl size=1175324 sha256=b3acfd520e0c346fb64bb26bcf104f24740142401f60636a29d2d92cafd733b1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zzw_77id/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\n",
            "Successfully built whisper\n",
            "Installing collected packages: ffmpeg-python, whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 whisper-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "transformers.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "m92DOPAEiyMV",
        "outputId": "6b943eae-3a42-4584-d43c-bc6081de90fa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.24.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFafUFnCi3cL",
        "outputId": "99e00af6-9d2e-4e11-fed8-9e3f79b18466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download youtube video"
      ],
      "metadata": {
        "id": "zmN1M1gB2LxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install youtube-dl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry1tE2hC2RI8",
        "outputId": "8dc90659-ca44-4397-bc5c-eb79ce4a7589"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting youtube-dl\n",
            "  Downloading youtube_dl-2021.12.17-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: youtube-dl\n",
            "Successfully installed youtube-dl-2021.12.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals\n",
        "import youtube_dl\n",
        "#https://www.youtube.com/watch?v=srSNZlbhCwk&t=3s\n",
        "\n",
        "ydl_opts = {\n",
        "    'format': 'bestaudio/best',\n",
        "    'postprocessors': [{\n",
        "        'key': 'FFmpegExtractAudio',\n",
        "        'preferredcodec': 'wav',\n",
        "        'preferredquality': '192',\n",
        "    }],\n",
        "    'outtmpl':\".\" + '/video.%(ext)s',\n",
        "}\n",
        "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "    ydl.download(['https://www.youtube.com/watch?v=srSNZlbhCwk&t=3s'])\n",
        "    \n",
        "absolute_path = \"output.wav\" #file name of your downloaded audio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOHt86zj2bIT",
        "outputId": "3a3d48eb-ed38-4ac0-a902-460bdb602c63"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] srSNZlbhCwk: Downloading webpage\n",
            "[download] Destination: ./video.webm\n",
            "[download] 100% of 763.32KiB in 00:14\n",
            "[ffmpeg] Destination: ./video.wav\n",
            "Deleting original file ./video.webm (pass -k to keep)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.io import wavfile\n",
        "import numpy as np\n",
        "\n",
        "data = wavfile.read(\"/content/video.wav\")\n",
        "framerate = data[0]\n",
        "sounddata = data[1]\n",
        "time = np.arange(0,len(sounddata))/framerate"
      ],
      "metadata": {
        "id": "bxXyNKZRQ1Rp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "framerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pm_KIueMRSk4",
        "outputId": "5e934f38-688a-4df9-8322-b83f254b4830"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44100"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"time {len(sounddata)/framerate} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qkbq6h1VRVSd",
        "outputId": "93641cf3-7267-4e41-8344-4ab1d4277806"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time 256.92879818594105 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
        "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UoEeWzFU9jF",
        "outputId": "e9217941-af28-4494-9966-668d32f84582"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
            "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:752: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
            "  warnings.warn(\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "speech, _ = librosa.load(\"/content/video.wav\",sr=16000)"
      ],
      "metadata": {
        "id": "qIejEIilWg03"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "input_values = tokenizer(speech, return_tensors=\"pt\").input_values\n",
        "logits = model(input_values).logits\n",
        "predicted_ids = torch.argmax(logits, dim=-1)\n",
        "transcription = tokenizer.batch_decode(predicted_ids)[0]"
      ],
      "metadata": {
        "id": "p49ZPkK2XK19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcription"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "N3UW-MFHYJhl",
        "outputId": "1a8c0f57-f770-4e5d-a0e4-003f1f8c2bcb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'YE BATAKI HEDGE A MEBARASALKATA MAPNI MOM GISAT I BANANI GI HANGIATA MARY MARMADI CA USA ME I COMPLUTETAT IS MA BOSARI GIM I TO MAMAGATI HI GIM KININ ARRAT OGE OSA BI PATI GI GA MECHADI GAN GANI ILI GAS IF I MU DI CHODI I TUGI MODI COMPUTEN MA GIM KINATAT A BE MADA MARMAGI CAMODI COLAAKUN GI CARKUPAN GERHOGE AN CAN MAYI TARAKAWAE A PASS ME HI HE AGO A LI I MAGA BONIPAS POTA TO MANA DICAKI CA GIVSITIS BETTI WHO HEV MAN OSUPUTA APKONO THOS NEPNI CHAKA DI CAI DO GI CAWI THE A MITI TA BE MANIN O DISKI GIO BA PI TA TEVA HAS SET TO NAN BATALCIN BA TE BAKTE MA BIROSO GAT JO MADDE AQULI COMANANIGI CA BETA WHO DE ASTA ME BUTTAS ALAKI VOTAKI'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration,WhisperFeatureExtractor\n",
        "import librosa\n",
        "\n",
        "speech, _ = librosa.load(\"/content/video.wav\",duration=56.8,sr=48000)\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\")\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large\")\n",
        "\n",
        "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language = \"en\", task = \"transcribe\")\n",
        "input_features = processor(speech, return_tensors=\"pt\").input_features \n",
        "predicted_ids = model.generate(input_features,max_length=3000)\n",
        "transcription = processor.batch_decode(predicted_ids)\n",
        "\n",
        "print(processor.batch_decode(predicted_ids, skip_special_tokens = True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIeflya0OEnM",
        "outputId": "2bfcfdc5-e3f1-4322-a24d-a41e1f6a417e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' I']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rh1ap69cYHnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "speech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnX8tJecT_ei",
        "outputId": "d9645c75-52ba-495e-c4c8-9bbb979d7414"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , ..., 0.00195312, 0.00198364,\n",
              "       0.0019989 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvR0z3IJT0nO",
        "outputId": "407e4039-2d20-4f27-97cd-edfd5dc8884f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.5945, -0.5945, -0.5945,  ...,  0.9885,  1.0717,  0.9540],\n",
              "         [-0.5945, -0.5945, -0.5945,  ...,  1.0158,  1.1478,  0.8460],\n",
              "         [-0.5945, -0.5945, -0.5945,  ...,  0.9025,  1.1163,  0.7533],\n",
              "         ...,\n",
              "         [-0.5945, -0.5945, -0.5945,  ..., -0.5945, -0.5945, -0.5945],\n",
              "         [-0.5945, -0.5945, -0.5945,  ..., -0.5945, -0.5945, -0.5945],\n",
              "         [-0.5945, -0.5945, -0.5945,  ..., -0.5945, -0.5945, -0.5945]]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperFeatureExtractor\n",
        "feature = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-large\")"
      ],
      "metadata": {
        "id": "Gm8ppxPvSw07"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature(speech)['input_features']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbWo575JS4dD",
        "outputId": "1ee98bef-caa6-4a5c-e261-20383cc367b8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.59445024, -0.59445024, -0.59445024, ...,  0.9884978 ,\n",
              "          1.0717466 ,  0.9539778 ],\n",
              "        [-0.59445024, -0.59445024, -0.59445024, ...,  1.0157536 ,\n",
              "          1.1478286 ,  0.8460471 ],\n",
              "        [-0.59445024, -0.59445024, -0.59445024, ...,  0.90251327,\n",
              "          1.1162922 ,  0.75329477],\n",
              "        ...,\n",
              "        [-0.59445024, -0.59445024, -0.59445024, ..., -0.59445024,\n",
              "         -0.59445024, -0.59445024],\n",
              "        [-0.59445024, -0.59445024, -0.59445024, ..., -0.59445024,\n",
              "         -0.59445024, -0.59445024],\n",
              "        [-0.59445024, -0.59445024, -0.59445024, ..., -0.59445024,\n",
              "         -0.59445024, -0.59445024]], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transcribe text from Audio"
      ],
      "metadata": {
        "id": "de7JA09ei9xN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"large\")\n",
        "options = dict(language='en', beam_size=5, best_of=5)\n",
        "#transcribe_options = dict(task=\"transcribe\", **options)\n",
        "translate_options = dict(task=\"translate\", **options)\n",
        "translation = model.transcribe(\"/content/video.wav\", **translate_options)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7XYvXwPk7kH",
        "outputId": "6d872b8c-8fcd-4dd7-9dd5-7deaeceb774e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 2.87G/2.87G [00:22<00:00, 136MiB/s]\n",
            "/usr/local/lib/python3.8/dist-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S29zdo7q6nYL",
        "outputId": "5b5c116b-1824-422c-9af2-be37e7f20238"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': \" This happened when I was 12 years old, I went to my grandmother's house with my mom My uncle had a computer at that time, which had a lot of games, so I started playing games as soon as I went there It was night and everyone went to attend the wedding in a nearby village except me Because I wanted to play games on the computer, then my uncle called me that his car has been punctured There is a tire in the house, we are close, come with the tire When I went to him, I saw that a strange thing was sitting, I asked him who are you Then he showed his face, which was very scary, then I noticed that he was just up to the stomach I ran immediately from there, but I fainted while running, when my eyes opened, I was at my grandmother's house I still don't know what it was\",\n",
              " 'segments': [{'id': 0,\n",
              "   'seek': 0,\n",
              "   'start': 0.0,\n",
              "   'end': 5.4,\n",
              "   'text': \" This happened when I was 12 years old, I went to my grandmother's house with my mom\",\n",
              "   'tokens': [639,\n",
              "    2011,\n",
              "    562,\n",
              "    286,\n",
              "    390,\n",
              "    2272,\n",
              "    924,\n",
              "    1331,\n",
              "    11,\n",
              "    286,\n",
              "    1437,\n",
              "    281,\n",
              "    452,\n",
              "    14317,\n",
              "    311,\n",
              "    1782,\n",
              "    365,\n",
              "    452,\n",
              "    1225],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3603224073137556,\n",
              "   'compression_ratio': 1.6905660377358491,\n",
              "   'no_speech_prob': 0.05138559639453888},\n",
              "  {'id': 1,\n",
              "   'seek': 0,\n",
              "   'start': 5.4,\n",
              "   'end': 11.4,\n",
              "   'text': ' My uncle had a computer at that time, which had a lot of games, so I started playing games as soon as I went there',\n",
              "   'tokens': [1222,\n",
              "    9153,\n",
              "    632,\n",
              "    257,\n",
              "    3820,\n",
              "    412,\n",
              "    300,\n",
              "    565,\n",
              "    11,\n",
              "    597,\n",
              "    632,\n",
              "    257,\n",
              "    688,\n",
              "    295,\n",
              "    2813,\n",
              "    11,\n",
              "    370,\n",
              "    286,\n",
              "    1409,\n",
              "    2433,\n",
              "    2813,\n",
              "    382,\n",
              "    2321,\n",
              "    382,\n",
              "    286,\n",
              "    1437,\n",
              "    456],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3603224073137556,\n",
              "   'compression_ratio': 1.6905660377358491,\n",
              "   'no_speech_prob': 0.05138559639453888},\n",
              "  {'id': 2,\n",
              "   'seek': 0,\n",
              "   'start': 11.4,\n",
              "   'end': 16.6,\n",
              "   'text': ' It was night and everyone went to attend the wedding in a nearby village except me',\n",
              "   'tokens': [467,\n",
              "    390,\n",
              "    1818,\n",
              "    293,\n",
              "    1518,\n",
              "    1437,\n",
              "    281,\n",
              "    6888,\n",
              "    264,\n",
              "    8523,\n",
              "    294,\n",
              "    257,\n",
              "    11184,\n",
              "    7288,\n",
              "    3993,\n",
              "    385],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3603224073137556,\n",
              "   'compression_ratio': 1.6905660377358491,\n",
              "   'no_speech_prob': 0.05138559639453888},\n",
              "  {'id': 3,\n",
              "   'seek': 0,\n",
              "   'start': 16.6,\n",
              "   'end': 22.5,\n",
              "   'text': ' Because I wanted to play games on the computer, then my uncle called me that his car has been punctured',\n",
              "   'tokens': [1436,\n",
              "    286,\n",
              "    1415,\n",
              "    281,\n",
              "    862,\n",
              "    2813,\n",
              "    322,\n",
              "    264,\n",
              "    3820,\n",
              "    11,\n",
              "    550,\n",
              "    452,\n",
              "    9153,\n",
              "    1219,\n",
              "    385,\n",
              "    300,\n",
              "    702,\n",
              "    1032,\n",
              "    575,\n",
              "    668,\n",
              "    27006,\n",
              "    3831],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3603224073137556,\n",
              "   'compression_ratio': 1.6905660377358491,\n",
              "   'no_speech_prob': 0.05138559639453888},\n",
              "  {'id': 4,\n",
              "   'seek': 0,\n",
              "   'start': 22.5,\n",
              "   'end': 26.400000000000002,\n",
              "   'text': ' There is a tire in the house, we are close, come with the tire',\n",
              "   'tokens': [821,\n",
              "    307,\n",
              "    257,\n",
              "    11756,\n",
              "    294,\n",
              "    264,\n",
              "    1782,\n",
              "    11,\n",
              "    321,\n",
              "    366,\n",
              "    1998,\n",
              "    11,\n",
              "    808,\n",
              "    365,\n",
              "    264,\n",
              "    11756],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.3603224073137556,\n",
              "   'compression_ratio': 1.6905660377358491,\n",
              "   'no_speech_prob': 0.05138559639453888},\n",
              "  {'id': 5,\n",
              "   'seek': 2640,\n",
              "   'start': 26.4,\n",
              "   'end': 32.199999999999996,\n",
              "   'text': ' When I went to him, I saw that a strange thing was sitting, I asked him who are you',\n",
              "   'tokens': [1133,\n",
              "    286,\n",
              "    1437,\n",
              "    281,\n",
              "    796,\n",
              "    11,\n",
              "    286,\n",
              "    1866,\n",
              "    300,\n",
              "    257,\n",
              "    5861,\n",
              "    551,\n",
              "    390,\n",
              "    3798,\n",
              "    11,\n",
              "    286,\n",
              "    2351,\n",
              "    796,\n",
              "    567,\n",
              "    366,\n",
              "    291],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.30966191011316635,\n",
              "   'compression_ratio': 1.5679611650485437,\n",
              "   'no_speech_prob': 2.2244217689149082e-05},\n",
              "  {'id': 6,\n",
              "   'seek': 2640,\n",
              "   'start': 32.199999999999996,\n",
              "   'end': 37.6,\n",
              "   'text': ' Then he showed his face, which was very scary, then I noticed that he was just up to the stomach',\n",
              "   'tokens': [1396,\n",
              "    415,\n",
              "    4712,\n",
              "    702,\n",
              "    1851,\n",
              "    11,\n",
              "    597,\n",
              "    390,\n",
              "    588,\n",
              "    6958,\n",
              "    11,\n",
              "    550,\n",
              "    286,\n",
              "    5694,\n",
              "    300,\n",
              "    415,\n",
              "    390,\n",
              "    445,\n",
              "    493,\n",
              "    281,\n",
              "    264,\n",
              "    9665],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.30966191011316635,\n",
              "   'compression_ratio': 1.5679611650485437,\n",
              "   'no_speech_prob': 2.2244217689149082e-05},\n",
              "  {'id': 7,\n",
              "   'seek': 2640,\n",
              "   'start': 37.6,\n",
              "   'end': 43.4,\n",
              "   'text': \" I ran immediately from there, but I fainted while running, when my eyes opened, I was at my grandmother's house\",\n",
              "   'tokens': [286,\n",
              "    5872,\n",
              "    4258,\n",
              "    490,\n",
              "    456,\n",
              "    11,\n",
              "    457,\n",
              "    286,\n",
              "    21104,\n",
              "    292,\n",
              "    1339,\n",
              "    2614,\n",
              "    11,\n",
              "    562,\n",
              "    452,\n",
              "    2575,\n",
              "    5625,\n",
              "    11,\n",
              "    286,\n",
              "    390,\n",
              "    412,\n",
              "    452,\n",
              "    14317,\n",
              "    311,\n",
              "    1782],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.30966191011316635,\n",
              "   'compression_ratio': 1.5679611650485437,\n",
              "   'no_speech_prob': 2.2244217689149082e-05},\n",
              "  {'id': 8,\n",
              "   'seek': 4340,\n",
              "   'start': 43.4,\n",
              "   'end': 56.8,\n",
              "   'text': \" I still don't know what it was\",\n",
              "   'tokens': [50364, 286, 920, 500, 380, 458, 437, 309, 390, 51034],\n",
              "   'temperature': 0.0,\n",
              "   'avg_logprob': -0.4710715033791282,\n",
              "   'compression_ratio': 0.7894736842105263,\n",
              "   'no_speech_prob': 0.0032498794607818127}],\n",
              " 'language': 'en'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "fQltOyu3nkuX",
        "outputId": "8cad770c-9964-4410-a627-b524955c9ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" This is when I was 12 years old, I once went to my grandmother's house with my mom. My uncle had a computer at that time, which had a lot of games, so I started playing games as soon as I went there. It was night and everyone went to attend the wedding in a nearby village, except me. Because I had to play games on the computer, then my uncle called me that his car has a puncture. There is a tire in the house, we are nearby, come with the tire. When I reached him, I saw that a strange thing was sitting, I asked him who you are. So he showed his face, which was very scary, then I noticed that it was just up to the stomach. I ran away from there, but while running I fainted. When I woke up, I was at my grandmother's house, I still don't know what it was.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the Automatic Speech Recognition Pipeline"
      ],
      "metadata": {
        "id": "pnGs9MTfszn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline(task=\"automatic-speech-recognition\", model=\"/content/drive/MyDrive/AFW/AIWispher/large\",max_length=5000,device=-1)\n",
        "pipe(\"/content/video.wav\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSxBgUQ2cDGT",
        "outputId": "c93fae0c-0322-4075-e7bf-49e6bae93406"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': \" This is when I was 12 years old I went to my grandmother's house with my mom My uncle had a computer at that time which had a lot of games So I started playing games as soon as I went there It was night and everyone went to attend the wedding in a nearby village except me Because I wanted to play games on the computer Then my uncle called me that his car has been punctured There is a tire in the house, we are close Come with the tire When I reached him, I saw that a strange thing was sitting\"}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe(\"/content/video.wav\")['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgHisfI9I3b5",
        "outputId": "ff79b6a0-b7ba-4b9b-8b87-b104cb5b8c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1387: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "0BZiRNvxJqch",
        "outputId": "93daf4dc-4c6c-4cf7-ca40-f1b9a325f0ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" This is when I was 12 years old I went to my grandmother's house with my mom My uncle had a computer at that time which had a lot of games So I started playing games as soon as I went there It was night and everyone went to attend the wedding in a nearby village except me Because I wanted to play games on the computer Then my uncle called me that his car has been punctured There is a tire in the house, we are close Come with the tire When I reached him, I saw that a strange thing was sitting\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zeroshot classification using transformers"
      ],
      "metadata": {
        "id": "eDepRUm9i4SQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.section.io/engineering-education/how-to-implement-zero-shot-classification-using-python/#:~:text=Zero-shot%20classification%20is%20a%20technique%20that%20allows%20us,topic%2C%20emotion%2C%20or%20event%20described%20by%20the%20label."
      ],
      "metadata": {
        "id": "XZlQV8hrptCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BU9fJopaBDH",
        "outputId": "def5e3f8-a536-4db3-d301-1b57c4df3260"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "classifier_pipeline = pipeline (\"zero-shot-classification\", model = \"facebook/bart-large-mnli\",device=-1)"
      ],
      "metadata": {
        "id": "8JAjDgGOi8N1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\n",
        "processor = AutoProcessor.from_pretrained(\"/content/drive/MyDrive/AFW/AIWispher/large\")\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\"/content/drive/MyDrive/AFW/AIWispher/large\",return_dict=False)"
      ],
      "metadata": {
        "id": "mxJHp6JPKw1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nlp= pipeline(\"automatic-speech-recognition\",\n",
        "                model=model,\n",
        "                tokenizer=processor,\n",
        "                framework=\"pt\", return_all_scores=False)\n",
        "\n",
        "encoded_input = tokenizer(article, truncation=True, max_length=512)\n",
        "decoded_input = tokenizer.decode(encoded_input[\"input_ids\"], skip_special_tokens = True)\n",
        "output = nlp(decoded_input)"
      ],
      "metadata": {
        "id": "LSofBLfhKhNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the zeroshot pipeline"
      ],
      "metadata": {
        "id": "BTOvnPLWr4KO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_pipeline.save_pretrained(\"/content/drive/MyDrive/AFW/Zeroshot\")"
      ],
      "metadata": {
        "id": "heMwchl9ptUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = \"\"\" This is when I was 12 years old I went to my grandmother's house with my mom My uncle had a computer at that time which had a lot of games So I started playing games as soon as I went there It was night and everyone went to attend the wedding in a nearby village except me Because I wanted to play games on the computer Then my uncle called me that his car has been punctured There is a tire in the house, we are close Come with the tire When I reached him, I saw that a strange thing was sitting\"\"\""
      ],
      "metadata": {
        "id": "AX5t8oo8tQwU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_pipeline = pipeline (\"zero-shot-classification\", model = \"/content/drive/MyDrive/AFW/Zeroshot\")\n",
        "label_candidate = ['Poistive','Negative','Neutral ']\n",
        "new_pipeline(result, label_candidate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDIwXSczJjrz",
        "outputId": "7ebdbeed-b388-466d-ab7b-3d73f3f23113"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': \" This is when I was 12 years old I went to my grandmother's house with my mom My uncle had a computer at that time which had a lot of games So I started playing games as soon as I went there It was night and everyone went to attend the wedding in a nearby village except me Because I wanted to play games on the computer Then my uncle called me that his car has been punctured There is a tire in the house, we are close Come with the tire When I reached him, I saw that a strange thing was sitting\",\n",
              " 'labels': ['Poistive', 'Negative', 'Neutral '],\n",
              " 'scores': [0.6192179322242737, 0.3039100170135498, 0.07687200605869293]}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\" This is when I was 12 years old, I once went to my grandmother's house with my mom. My uncle had a computer at that time, which had a lot of games, so I started playing games as soon as I went there. It was night and everyone went to attend the wedding in a nearby village, except me. Because I had to play games on the computer, then my uncle called me that his car has a puncture. There is a tire in the house, we are nearby, come with the tire. When I reached him, I saw that a strange thing was sitting, I asked him who you are. So he showed his face, which was very scary, then I noticed that it was just up to the stomach. I ran away from there, but while running I fainted. When I woke up, I was at my grandmother's house, I still don't know what it was.\"\"\""
      ],
      "metadata": {
        "id": "7VJExfmLqdfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_pipeline = pipeline (\"zero-shot-classification\", model = \"/content/zeroshot\")\n",
        "label_candidate = ['horror', 'comedy', 'sentimental','romantic','seroius','tragedy']\n",
        "new_pipeline(text, label_candidate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUGNXhB5qBPC",
        "outputId": "728d0a53-f75b-4f60-c0e5-7028bb4a266a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': \" This is when I was 12 years old, I once went to my grandmother's house with my mom. My uncle had a computer at that time, which had a lot of games, so I started playing games as soon as I went there. It was night and everyone went to attend the wedding in a nearby village, except me. Because I had to play games on the computer, then my uncle called me that his car has a puncture. There is a tire in the house, we are nearby, come with the tire. When I reached him, I saw that a strange thing was sitting, I asked him who you are. So he showed his face, which was very scary, then I noticed that it was just up to the stomach. I ran away from there, but while running I fainted. When I woke up, I was at my grandmother's house, I still don't know what it was.\",\n",
              " 'labels': ['horror', 'seroius', 'sentimental', 'comedy', 'romantic'],\n",
              " 'scores': [0.6341521739959717,\n",
              "  0.18177475035190582,\n",
              "  0.12192074954509735,\n",
              "  0.037401482462882996,\n",
              "  0.02475087158381939]}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_candidate = ['Positive', 'Negative', 'Neutral']\n",
        "classifier_pipeline (translation['text'], label_candidate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm2kB9C_pb_N",
        "outputId": "0e98b440-538d-4aa3-dbc5-ebcb52d14204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': \" This is when I was 12 years old, I once went to my grandmother's house with my mom. My uncle had a computer at that time, which had a lot of games, so I started playing games as soon as I went there. It was night and everyone went to attend the wedding in a nearby village, except me. Because I had to play games on the computer, then my uncle called me that his car has a puncture. There is a tire in the house, we are nearby, come with the tire. When I reached him, I saw that a strange thing was sitting, I asked him who you are. So he showed his face, which was very scary, then I noticed that it was just up to the stomach. I ran away from there, but while running I fainted. When I woke up, I was at my grandmother's house, I still don't know what it was.\",\n",
              " 'labels': ['Negative', 'Positive', 'Neutral'],\n",
              " 'scores': [0.520041286945343, 0.24548503756523132, 0.23447363078594208]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Huggingface whisper model"
      ],
      "metadata": {
        "id": "PvcfYlKIsPqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration,WhisperFeatureExtractor"
      ],
      "metadata": {
        "id": "Rnxg5raD--Oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\")\n",
        "feature = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-large\")\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large\")"
      ],
      "metadata": {
        "id": "KnjH4vMn--81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newm = whisper.load_audio('/content/video.wav')"
      ],
      "metadata": {
        "id": "nLDC5T6YBJPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newm.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqpPM4oPequL",
        "outputId": "76777127-0566-43fc-9ec7-f5ce95efddbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(731440,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation = newm.transcribe(\"/content/Audio1.mp3\", **translate_options)\n"
      ],
      "metadata": {
        "id": "aFoKqcMRBZqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration,WhisperFeatureExtractor\n",
        "\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\")\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large\")\n",
        "processor.save_pretrained(\"/content/drive/MyDrive/AFW/AIWispher/\")\n",
        "model.save_pretrained(\"/content/drive/MyDrive/AFW/AIWispher/\")"
      ],
      "metadata": {
        "id": "-BHBQFiH9y3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-large\")"
      ],
      "metadata": {
        "id": "70m1Cf8A0Gpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat.save_pretrained(\"/content/drive/MyDrive/AFW/AIWispher/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI2zUPO90Msc",
        "outputId": "ba9d81dc-ef29-4a3e-ee5e-8ce4c92ccd1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/AFW/AIWispher/preprocessor_config.json']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\"openai/whisper-large\")\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\"openai/whisper-large\")"
      ],
      "metadata": {
        "id": "J9-vM_3H27-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor.save_pretrained(\"/content/whispmodel/\")"
      ],
      "metadata": {
        "id": "T1CRBtnp3fK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"whispmodel\")"
      ],
      "metadata": {
        "id": "9lDTCWge3Bu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "newmodel = whisper.load_model(\"/content/drive/MyDrive/AFW/AIWispher/large/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "LkK2cRL_zgBA",
        "outputId": "32f242bc-178a-4673-87c8-be1cd2113450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-53bad1bbb681>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnewmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/AFW/AIWispher/large/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/whisper/__init__.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, device, download_root, in_memory)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mcheckpoint_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0min_memory\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model {name} not found; available models = {available_models()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0min_memory\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Model /content/drive/MyDrive/AFW/AIWispher/large/ not found; available models = ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large-v1', 'large-v2', 'large']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "whisper.available_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87R-WlY8Hme0",
        "outputId": "e1302bf9-eea9-4f77-e909-74642e0a7c03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tiny.en',\n",
              " 'tiny',\n",
              " 'base.en',\n",
              " 'base',\n",
              " 'small.en',\n",
              " 'small',\n",
              " 'medium.en',\n",
              " 'medium',\n",
              " 'large-v1',\n",
              " 'large-v2',\n",
              " 'large']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9aWe6UJm3gC",
        "outputId": "10394d9a-9953-4ecc-bd1c-cc47cbb783d2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (0.8.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.4.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.11.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (59.5.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (4.13.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.43.0->librosa) (3.11.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Librosa can handle videos spanning upto 30 seconds"
      ],
      "metadata": {
        "id": "g55M8aHhq0o0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "import librosa\n",
        "\n",
        "speech, _ = librosa.load(\"/content/video.wav\")\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\")\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large\")\n",
        "\n",
        "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language = \"en\", task = \"transcribe\")\n",
        "input_features = processor(speech, return_tensors=\"pt\").input_features \n",
        "predicted_ids = model.generate(input_features,max_length=1000)\n",
        "transcription = processor.batch_decode(predicted_ids)\n",
        "\n",
        "print(processor.batch_decode(predicted_ids, skip_special_tokens = True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG8S0BA1lvsP",
        "outputId": "ff9b3e95-df5a-4a8a-e89a-c7f4d99098fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\" This is when I was 12 years old, I went to my grandmother's house with my mom. My uncle had a computer at that time, which had a lot of games, so I went there and started playing games. It was night and everyone went to attend the wedding in a nearby village except me, because I wanted to play games on the computer. Then my uncle called me and said that his car's\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_ids = model.generate(input_features,max_new_tokens=3000)\n",
        "transcription = processor.batch_decode(predicted_ids)\n",
        "\n",
        "print(processor.batch_decode(predicted_ids, skip_special_tokens = True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPUM5DpXpDsF",
        "outputId": "818179d1-3c87-4e8b-f5e1-74457297c25c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\" This is when I was 12 years old, I went to my grandmother's house with my mom. My uncle had a computer at that time, which had a lot of games, so I went there and started playing games. It was night and everyone went to attend the wedding in a nearby village except me, because I wanted to play games on the computer. Then my uncle called me and said that his car's\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference script"
      ],
      "metadata": {
        "id": "FJmNj9Bpae0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/video.wav', mode='rb') as f:\n",
        "    response = f.read()"
      ],
      "metadata": {
        "id": "ZTRjbqfIaqSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "TxkQ-vsxgbpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import whisper\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "import os\n",
        "import json\n",
        "import io\n",
        "import wave\n",
        "\n",
        "import numpy as np\n",
        "import scipy.io.wavfile\n",
        "import soundfile as sf\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "# \n",
        "def convert_bytearray_to_wav_ndarray(input_bytearray: bytes, sampling_rate=16000):\n",
        "    bytes_wav = bytes()\n",
        "    byte_io = io.BytesIO(bytes_wav)\n",
        "    write(byte_io, sampling_rate, np.frombuffer(input_bytearray, dtype=np.int16))\n",
        "    output_wav = byte_io.read()\n",
        "    output, samplerate = sf.read(io.BytesIO(output_wav))\n",
        "    return output\n",
        "   \n",
        "#\n",
        "\n",
        "def preprocess_function(data_path,content_type = None ):\n",
        "    \"\"\"\n",
        "    wf = wave.open(data_path, 'rb')\n",
        "    chunk = 1024\n",
        "    audio_input = b''\n",
        "    d = wf.readframes(chunk)\n",
        "    while len(d) > 0:\n",
        "        d = wf.readframes(chunk)\n",
        "        audio_input = audio_input + d\n",
        "    output = convert_bytearray_to_wav_ndarray(input_bytearray=audio_input)\n",
        "    scipy.io.wavfile.write(\"output.wav\", 16000, output)\n",
        "    file_path = \"output.wav\"\n",
        "    \"\"\"\n",
        "    #file_path = data_path\n",
        "    return data_path\n",
        "\n",
        "# \n",
        "def predict_function(file_path,model): \n",
        "    print(\"predict function\\n\")\n",
        "    asr,nlp = model\n",
        "    translation = asr(file_path)\n",
        "    text = translation['text']\n",
        "    label_candidate = ['positive','negative','neutral']\n",
        "    result = nlp(text, label_candidate)\n",
        "    print(result)\n",
        "    return result\n",
        "#\n",
        "def model_load_function(model_file_path):\n",
        "    pipe = pipeline(task=\"automatic-speech-recognition\", model=model_file_path[0],device=-1)\n",
        "    nlp_pipeline = pipeline (\"zero-shot-classification\", model = model_file_path[1],device=-1)\n",
        "    return (pipe,nlp_pipeline)\n",
        "#\n",
        "def postprocess_function(predictions,content_type = None ):\n",
        "    output = {}\n",
        "    for k,v in zip(predictions['labels'],predictions['scores']):\n",
        "        output[k] = round(v * 100.0,2)\n",
        "        return json.dumps({\"response\": \"Audio Sentiment detected {}\".format(output)})\n",
        "\n",
        "# test the script\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    file_name = \"video.wav\"\n",
        "    model_file_path = [\"/content/drive/MyDrive/AFW/AIWispher/large\",\"/content/drive/MyDrive/AFW/Zeroshot\"]\n",
        "    model = model_load_function(model_file_path)\n",
        "    input_data = preprocess_function(file_name)\n",
        "    summary = predict_function(input_data, model)\n",
        "    output = postprocess_function(summary)\n",
        "    print(output)\n",
        "    \n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "w9xgcoOSag3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a2050be-a71c-40e9-87f2-058309d9409d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predict function\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sequence': \" This is when I was 12 years old I went to my grandmother's house with my mom My uncle had a computer at that time which had a lot of games So I started playing games as soon as I went there It was night and everyone went to attend the wedding in a nearby village except me Because I wanted to play games on the computer Then my uncle called me that his car has been punctured There is a tire in the house, we are close Come with the tire When I reached him, I saw that a strange thing was sitting\", 'labels': ['negative', 'neutral', 'positive'], 'scores': [0.8818128705024719, 0.08331611007452011, 0.03487100079655647]}\n",
            "{\"response\": \"Audio Sentiment detected {'negative': 88.18}\"}\n"
          ]
        }
      ]
    }
  ]
}