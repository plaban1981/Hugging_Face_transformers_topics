{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plaban1981/Hugging_Face_transformers_topics/blob/main/Paraphrasing_with_Transformers_PythonCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzM7aw7wwXX3",
        "outputId": "4a76eac8-6c06-4b87-eb66-3346b762296e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.22.0-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 4.0 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 44.6 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 62.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 34.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Collecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 55.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=83057efcf86ed505f8f52c7f678a3664a7c15527e2a89137689a22c90c5f4adc\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, sentencepiece, sacremoses\n",
            "Successfully installed huggingface-hub-0.9.1 sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.12.1 transformers-4.22.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers sentencepiece sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISeIFTv3wbBP"
      },
      "outputs": [],
      "source": [
        "from transformers import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCFD-rjqm8Mm"
      },
      "outputs": [],
      "source": [
        "# models we gonna use for this tutorial\n",
        "model_names = [\n",
        "  \"tuner007/pegasus_paraphrase\",\n",
        "  \"Vamsi/T5_Paraphrase_Paws\",\n",
        "  \"prithivida/parrot_paraphraser_on_T5\", # Parrot\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 35,
          "referenced_widgets": [
            "a2a547a887f44b148234ef1acbc08b70",
            "2d430f3a100742bc856ace0de32a9b93",
            "be865d9312324cabab3bbfc0c2e57ae8",
            "ab51d7129d36473ea6450bc4b0350c4a",
            "fb00f75e392b48698597c5024e6c37d2"
          ]
        },
        "id": "PgrQWA_2whqN",
        "outputId": "4dad5282-c89f-4405-ffb0-42a91e7fb5c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpo2mpdb3_\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2a547a887f44b148234ef1acbc08b70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/d6a784b31cbe212ac3dabbc78bc4e454cf9d8a1b11ff2ef1ba1c7497f2bbfb33.7a3e093739f407bcc025e64dfc5244f91bc573ed4285cba53de90f960cbce58e\n",
            "creating metadata file for /root/.cache/huggingface/transformers/d6a784b31cbe212ac3dabbc78bc4e454cf9d8a1b11ff2ef1ba1c7497f2bbfb33.7a3e093739f407bcc025e64dfc5244f91bc573ed4285cba53de90f960cbce58e\n",
            "loading configuration file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/d6a784b31cbe212ac3dabbc78bc4e454cf9d8a1b11ff2ef1ba1c7497f2bbfb33.7a3e093739f407bcc025e64dfc5244f91bc573ed4285cba53de90f960cbce58e\n",
            "Model config PegasusConfig {\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 1,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 60,\n",
            "  \"max_position_embeddings\": 60,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"transformers_version\": \"4.19.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 96103\n",
            "}\n",
            "\n",
            "https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpgdj95q6p\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d430f3a100742bc856ace0de32a9b93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.12G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/227d9f57dd37c1f4f5be77ccf5f896e7551ec64db897d21c4613d235eb9cc73a.9e93d391568a0e6e2b8408cd2311ebfa97682e0e0bd8b83a631ab7ad40e93905\n",
            "creating metadata file for /root/.cache/huggingface/transformers/227d9f57dd37c1f4f5be77ccf5f896e7551ec64db897d21c4613d235eb9cc73a.9e93d391568a0e6e2b8408cd2311ebfa97682e0e0bd8b83a631ab7ad40e93905\n",
            "loading weights file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/227d9f57dd37c1f4f5be77ccf5f896e7551ec64db897d21c4613d235eb9cc73a.9e93d391568a0e6e2b8408cd2311ebfa97682e0e0bd8b83a631ab7ad40e93905\n",
            "All model checkpoint weights were used when initializing PegasusForConditionalGeneration.\n",
            "\n",
            "All the weights of PegasusForConditionalGeneration were initialized from the model checkpoint at tuner007/pegasus_paraphrase.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use PegasusForConditionalGeneration for predictions without further training.\n",
            "https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp8tpv7gh8\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be865d9312324cabab3bbfc0c2e57ae8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/86.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/3f72dece4d3fcab1480f78a2c2a1f6ab591bb9b77ec8b049f8faa418bd50526d.f96255d0af339b1faae306ed2925a98f5266a4ebbf793a8bca5107f6e0f876dd\n",
            "creating metadata file for /root/.cache/huggingface/transformers/3f72dece4d3fcab1480f78a2c2a1f6ab591bb9b77ec8b049f8faa418bd50526d.f96255d0af339b1faae306ed2925a98f5266a4ebbf793a8bca5107f6e0f876dd\n",
            "https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/spiece.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpy1ww8uyt\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab51d7129d36473ea6450bc4b0350c4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/spiece.model in cache at /root/.cache/huggingface/transformers/b3949a7257f9b4eaaf4f7785be079d89e4fec7d1c3763a58e6a2743635877d1f.1acf68c74589da6c7fa3548093824dfc450a54637f4356929bbfea7e294a68f8\n",
            "creating metadata file for /root/.cache/huggingface/transformers/b3949a7257f9b4eaaf4f7785be079d89e4fec7d1c3763a58e6a2743635877d1f.1acf68c74589da6c7fa3548093824dfc450a54637f4356929bbfea7e294a68f8\n",
            "https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpbxazutrz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb00f75e392b48698597c5024e6c37d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/1ff5597b098cfe2ee6d3b0c4b3e94e549fcb86f2e033146119d1591f6e4c4166.294ebaa4cd17bb284635004c92d2c4d522ec488c828dcce0c2471b6f28e3fe82\n",
            "creating metadata file for /root/.cache/huggingface/transformers/1ff5597b098cfe2ee6d3b0c4b3e94e549fcb86f2e033146119d1591f6e4c4166.294ebaa4cd17bb284635004c92d2c4d522ec488c828dcce0c2471b6f28e3fe82\n",
            "loading file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/b3949a7257f9b4eaaf4f7785be079d89e4fec7d1c3763a58e6a2743635877d1f.1acf68c74589da6c7fa3548093824dfc450a54637f4356929bbfea7e294a68f8\n",
            "loading file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/1ff5597b098cfe2ee6d3b0c4b3e94e549fcb86f2e033146119d1591f6e4c4166.294ebaa4cd17bb284635004c92d2c4d522ec488c828dcce0c2471b6f28e3fe82\n",
            "loading file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/3f72dece4d3fcab1480f78a2c2a1f6ab591bb9b77ec8b049f8faa418bd50526d.f96255d0af339b1faae306ed2925a98f5266a4ebbf793a8bca5107f6e0f876dd\n",
            "loading configuration file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/d6a784b31cbe212ac3dabbc78bc4e454cf9d8a1b11ff2ef1ba1c7497f2bbfb33.7a3e093739f407bcc025e64dfc5244f91bc573ed4285cba53de90f960cbce58e\n",
            "Model config PegasusConfig {\n",
            "  \"_name_or_path\": \"tuner007/pegasus_paraphrase\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 1,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 60,\n",
            "  \"max_position_embeddings\": 60,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"transformers_version\": \"4.19.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 96103\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/d6a784b31cbe212ac3dabbc78bc4e454cf9d8a1b11ff2ef1ba1c7497f2bbfb33.7a3e093739f407bcc025e64dfc5244f91bc573ed4285cba53de90f960cbce58e\n",
            "Model config PegasusConfig {\n",
            "  \"_name_or_path\": \"tuner007/pegasus_paraphrase\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 1,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 60,\n",
            "  \"max_position_embeddings\": 60,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"transformers_version\": \"4.19.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 96103\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = PegasusForConditionalGeneration.from_pretrained(\"tuner007/pegasus_paraphrase\")\n",
        "tokenizer = PegasusTokenizerFast.from_pretrained(\"tuner007/pegasus_paraphrase\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hPtX7UCfys__"
      },
      "outputs": [],
      "source": [
        "def get_paraphrased_sentences(model, tokenizer, sentence, num_return_sequences=5, num_beams=5):\n",
        "  # tokenize the text to be form of a list of token IDs\n",
        "  inputs = tokenizer([sentence], truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "  # generate the paraphrased sentences\n",
        "  outputs = model.generate(\n",
        "    **inputs,\n",
        "    num_beams=num_beams,\n",
        "    num_return_sequences=num_return_sequences,\n",
        "  )\n",
        "  # decode the generated sentences using the tokenizer to get them back to text\n",
        "  return tokenizer.batch_decode(outputs, skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9hG1HJR3Gb0Q"
      },
      "outputs": [],
      "source": [
        "sentence = \"Learning is the process of acquiring new understanding, knowledge, behaviors, skills, values, attitudes, and preferences.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6P2tbSy4zdZk"
      },
      "outputs": [],
      "source": [
        "get_paraphrased_sentences(model, tokenizer, sentence, num_beams=10, num_return_sequences=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4amSI3uw7RlT"
      },
      "outputs": [],
      "source": [
        "get_paraphrased_sentences(model, tokenizer, \"To paraphrase a source, you have to rewrite a passage without changing the meaning of the original text.\", num_beams=10, num_return_sequences=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1M5tOdBNB6VR"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ONGGLOMHUtF"
      },
      "outputs": [],
      "source": [
        "get_paraphrased_sentences(model, tokenizer, \"paraphrase: \" + \"One of the best ways to learn is to teach what you've already learned\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wzo28toRzhGZ"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/PrithivirajDamodaran/Parrot_Paraphraser.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMFGB_iZANLt"
      },
      "outputs": [],
      "source": [
        "from parrot import Parrot\n",
        "\n",
        "parrot = Parrot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5yWdZ_mAXp8",
        "outputId": "3b074251-7a50-4a12-f4e0-3d6bfb620e85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Input_phrase:  Learning is the process of acquiring new understanding, knowledge, behaviors, skills, values, attitudes, and preferences.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "('learning is the process of learning to understand knowledge behaviors values attitudes and preferences', 32)\n",
            "('learning is the process of acquiring new knowledge behaviors skills values attitudes and preferences', 27)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Input_phrase:  One of the best ways to learn is to teach what you've already learned\n",
            "----------------------------------------------------------------------------------------------------\n",
            "('one of the best ways to learn is to teach what you know', 29)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Input_phrase:  Paraphrasing is the process of coming up with someone else's ideas in your own words\n",
            "----------------------------------------------------------------------------------------------------\n",
            "(\"paraphrasing is the process of bringing up another's ideas in your own words\", 32)\n",
            "(\"paraphrasing is the process of coming up with another's ideas in your own words\", 22)\n",
            "(\"paraphrasing is the process of coming up with somebody else's ideas in your own words\", 15)\n",
            "(\"paraphrasing is the process of coming up with someone else's ideas in your own words\", 12)\n"
          ]
        }
      ],
      "source": [
        "phrases = [\n",
        "  sentence,\n",
        "  \"One of the best ways to learn is to teach what you've already learned\",\n",
        "  \"Paraphrasing is the process of coming up with someone else's ideas in your own words\"\n",
        "]\n",
        "\n",
        "for phrase in phrases:\n",
        "  print(\"-\"*100)\n",
        "  print(\"Input_phrase: \", phrase)\n",
        "  print(\"-\"*100)\n",
        "  paraphrases = parrot.augment(input_phrase=phrase)\n",
        "  for paraphrase in paraphrases:\n",
        "   print(paraphrase)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}